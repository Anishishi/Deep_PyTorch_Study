{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PSPNet(nn.Module):\n",
    "    def __init__(self,n_classes):\n",
    "        super(PSPNet,self).__init__()\n",
    "        \n",
    "        #set parameters\n",
    "        block_config=[3,4,6,3] #resnet50\n",
    "        img_size=475\n",
    "        img_size_8=60 #img_sizeの1/8に\n",
    "        \n",
    "        #4つのモジュールを構成するサブネットワークの用意\n",
    "        self.feature_conv=FeatureMap_convolution()\n",
    "        self.feature_res_1=ResidualBlockPSP(n_blocks=block_config[0],in_channels=128,mid_channels=64,out_channels=256,stride=1,dilation=1)\n",
    "        self.feature_res_2=ResidualBlockPSP(n_blocks=block_config[1],in_channels=256,mid_channels=128,out_channels=512,stride=2,dilation=1)\n",
    "        self.feature_dilated_res_1=ResidualBlockPSP(\n",
    "            n_blocks=block_config[2],in_channels=512,mid_channels=256,out_channels=1024,stride=1,dilation=2)\n",
    "        self.feature_dilated_res_2=ResidualBlockPSP(\n",
    "            n_blocks=block_config[3],in_channels=1024,mid_channels=512,out_channels=2048,stride=1,dilation=4)\n",
    "        \n",
    "        self.pyramid_pooling=PyramidPooling(in_channels=2048,pool_sizes=[6,3,2,1],height=img_size_8,width=img_size_8)\n",
    "        \n",
    "        self.decode_feature=DecoderPSPFeature(height=img_size,width=img_size,n_classes=n_classes)\n",
    "        \n",
    "        self.aux=AuxiliaryPSPlayers(in_channels=1024,height=img_size,width=img_size,n_classes=n_classes)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x=self.feature_conv(x)\n",
    "        x=self.feature_res_1(x)\n",
    "        x=self.feature_res_2(x)\n",
    "        x=self.feature_dilated_res_1(x)\n",
    "        output_aux=self.aux(x) #Feature-moduleの途中をAux-moduleへ\n",
    "        \n",
    "        x=self.feature_dilated_res_2(x)\n",
    "        \n",
    "        x=self.pyramid_pooling(x)\n",
    "        output=self.decode_feature(x)\n",
    "        \n",
    "        return (output, output_aux)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class conv2DBatchNormRelu(nn.Module):\n",
    "    def __init__(self,in_channels,out_channels,kernel_size,stride,padding,dilation,bias):\n",
    "        super(conv2DBatchNormRelu,self).__init__()\n",
    "        self.conv=nn.Conv2d(in_channels,out_channels,kernel_size,stride,padding,dilation,bias=bias)\n",
    "        self.batchnorm=nn.BatchNorm2d(out_channels)\n",
    "        self.relu=nn.ReLU(inplace=True)\n",
    "        #inplace設定では入力を保存せず出力を計算し，メモリを削減する\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x=self.conv(x)\n",
    "        x=self.batchnorm(x)\n",
    "        outputs=self.relu(x)\n",
    "        \n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeatureMap_convolution(nn.Module):\n",
    "    def __init__(self):\n",
    "        #構成するネットワークを用意\n",
    "        super(FeatureMap_convolution, self).__init__()\n",
    "        \n",
    "        #畳み込み層1\n",
    "        in_channels, out_channels, kernel_size, stride, padding, dilation, bias=3,64,3,2,1,1,False\n",
    "        self.cbnr_1=conv2DBatchNormRelu(in_channels,out_channels,kernel_size,stride,padding,dilation,bias)\n",
    "        \n",
    "        #畳み込み層2\n",
    "        in_channels, out_channels, kernel_size, stride, padding, dilation, bias=64,64,3,1,1,1,False\n",
    "        self.cbnr_2=conv2DBatchNormRelu(in_channels,out_channels,kernel_size,stride,padding,dilation,bias)\n",
    "        \n",
    "        #畳み込み層3\n",
    "        in_channels, out_channels, kernel_size, stride, padding, dilation, bias=64,128,3,1,1,1,False\n",
    "        self.cbnr_3=conv2DBatchNormRelu(in_channels,out_channels,kernel_size,stride,padding,dilation,bias)\n",
    "        \n",
    "        #MaxPooling層\n",
    "        self.maxpool=nn.MaxPool2d(kernel_size=3,stride=2,padding=1)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        x=self.cbnr_1(x)\n",
    "        x=self.cbnr_2(x)\n",
    "        x=self.cbnr_3(x)\n",
    "        outputs=self.maxpool(x)\n",
    "        \n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResidualBlockPSP(nn.Sequential):\n",
    "    def __init__(self,n_blocks,in_channels,mid_channels,out_channels,stride,dilation):\n",
    "        super(ResidualBlockPSP,self).__init__()\n",
    "        \n",
    "        #bottleNeckPSPの用意\n",
    "        self.add_module(\"block1\",bottleNeckPSP(in_channels,mid_channels,out_channels,stride,dilation))\n",
    "        \n",
    "        #bottleNeckPSPの繰り返し用意\n",
    "        for i in range(n_blocks-1):\n",
    "            self.add_module(\"block\"+str(i+2),bottleNeckIdentifyPSP(out_channels,mid_channels,stride,dilation))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class conv2DBatchNorm(nn.Module):\n",
    "    def __init__(self,in_channels,out_channels,kernel_size,stride,padding,dilation,bias):\n",
    "        super(conv2DBatchNorm,self).__init__()\n",
    "        self.conv=nn.Conv2d(in_channels,out_channels,kernel_size,stride,padding,dilation,bias=bias)\n",
    "        self.batchnorm=nn.BatchNorm2d(out_channels)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        x=self.conv(x)\n",
    "        outputs=self.batchnorm(x)\n",
    "        \n",
    "        return outputs\n",
    "    \n",
    "class bottleNeckPSP(nn.Module):\n",
    "    def __init__(self,in_channels,mid_channels,out_channels,stride,dilation):\n",
    "        super(bottleNeckPSP,self).__init__()\n",
    "        \n",
    "        self.cbr_1=conv2DBatchNormRelu(in_channels,mid_channels,kernel_size=1,stride=1,padding=0,dilation=1,bias=False)\n",
    "        self.cbr_2=conv2DBatchNormRelu(mid_channels,mid_channels,kernel_size=3,stride=stride,padding=dilation,dilation=dilation,bias=False)\n",
    "        self.cb_3=conv2DBatchNorm(mid_channels,out_channels,kernel_size=1,stride=1,padding=0,dilation=1,bias=False)\n",
    "        \n",
    "        #スキップ結合\n",
    "        self.cb_residual=conv2DBatchNorm(in_channels,out_channels,kernel_size=1,stride=stride,padding=0,dilation=1,bias=False)\n",
    "        \n",
    "        self.relu=nn.ReLU(inplace=True)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        conv=self.cb_3(self.cbr_2(self.cbr_1(x)))\n",
    "        residual=self.cb_residual(x)\n",
    "        return self.relu(conv+residual)\n",
    "    \n",
    "class bottleNeckIdentifyPSP(nn.Module):\n",
    "    def __init__(self,in_channels,mid_channels,stride,dilation):\n",
    "        super(bottleNeckIdentifyPSP,self).__init__()\n",
    "        \n",
    "        self.cbr_1=conv2DBatchNormRelu(in_channels,mid_channels,kernel_size=1,stride=1,padding=0,dilation=1,bias=False)\n",
    "        self.cbr_2=conv2DBatchNormRelu(mid_channels,mid_channels,kernel_size=3,stride=1,padding=dilation,dilation=dilation,bias=False)\n",
    "        self.cb_3=conv2DBatchNorm(mid_channels,in_channels,kernel_size=1,stride=1,padding=0,dilation=1,bias=False)\n",
    "        self.relu=nn.ReLU(inplace=True)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        conv=self.cb_3(self.cbr_2(self.cbr_1(x)))\n",
    "        residual=x\n",
    "        return self.relu(conv+residual)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PyramidPooling(nn.Module):\n",
    "    def __init__(self,in_channels,pool_sizes,height,width):\n",
    "        super(PyramidPooling,self).__init__()\n",
    "        \n",
    "        \n",
    "        #forwardで使用する画像サイズ\n",
    "        self.height=height\n",
    "        self.width=width\n",
    "        \n",
    "        #各畳み込み層の出力チャネル数\n",
    "        out_channels=int(in_channels/len(pool_sizes))\n",
    "        \n",
    "        #各畳込み層作成．\n",
    "        #この実装方法は愚直すぎてfor文で書きたいがわかりやすさのため以下のように書く\n",
    "        #pool_sizes:[6,3,2,1]\n",
    "        self.avpool_1=nn.AdaptiveAvgPool2d(output_size=pool_sizes[0])\n",
    "        self.cbr_1=conv2DBatchNormRelu(in_channels,out_channels,kernel_size=1,stride=1,padding=0,dilation=1,bias=False)\n",
    "        \n",
    "        self.avpool_2=nn.AdaptiveAvgPool2d(output_size=pool_sizes[1])\n",
    "        self.cbr_2=conv2DBatchNormRelu(in_channels,out_channels,kernel_size=1,stride=1,padding=0,dilation=1,bias=False)\n",
    "        \n",
    "        self.avpool_3=nn.AdaptiveAvgPool2d(output_size=pool_sizes[2])\n",
    "        self.cbr_3=conv2DBatchNormRelu(in_channels,out_channels,kernel_size=1,stride=1,padding=0,dilation=1,bias=False)\n",
    "        \n",
    "        self.avpool_4=nn.AdaptiveAvgPool2d(output_size=pool_sizes[3])\n",
    "        self.cbr_4=conv2DBatchNormRelu(in_channels,out_channels,kernel_size=1,stride=1,padding=0,dilation=1,bias=False)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        \n",
    "        out1=self.cbr_1(self.avpool_1(x))\n",
    "        out1=F.interpolate(out1,size=(self.height, self.width),mode=\"bilinear\", align_corners=True)\n",
    "        \n",
    "        out2=self.cbr_2(self.avpool_2(x))\n",
    "        out2=F.interpolate(out2,size=(self.height, self.width),mode=\"bilinear\", align_corners=True)\n",
    "        \n",
    "        out3=self.cbr_3(self.avpool_3(x))\n",
    "        out3=F.interpolate(out3,size=(self.height, self.width),mode=\"bilinear\", align_corners=True)\n",
    "        \n",
    "        out4=self.cbr_4(self.avpool_4(x))\n",
    "        out4=F.interpolate(out4,size=(self.height, self.width),mode=\"bilinear\", align_corners=True)\n",
    "        \n",
    "        #finally concatenate all paths\n",
    "        output=torch.cat([x,out1,out2,out3,out4],dim=1)\n",
    "        \n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderPSPFeature(nn.Module):\n",
    "    def __init__(self,height,width,n_classes):\n",
    "        super(DecoderPSPFeature,self).__init__()\n",
    "        \n",
    "        #forwardで使用する画像サイズ\n",
    "        self.height=height\n",
    "        self.width=width\n",
    "        \n",
    "        self.cbr=conv2DBatchNormRelu(in_channels=4096,out_channels=512,kernel_size=3,stride=1,padding=1,dilation=1,bias=False)\n",
    "        self.dropout=nn.Dropout2d(p=0.1)\n",
    "        self.classification=nn.Conv2d(in_channels=512,out_channels=n_classes,kernel_size=1,stride=1,padding=0)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        x=self.cbr(x)\n",
    "        x=self.dropout(x)\n",
    "        x=self.classification(x)\n",
    "        output=F.interpolate(x,size=(self.height,self.width),mode=\"bilinear\",align_corners=True)\n",
    "        \n",
    "        return output\n",
    "    \n",
    "    \n",
    "class AuxiliaryPSPlayers(nn.Module):\n",
    "    def __init__(self,in_channels,height,width,n_classes):\n",
    "        super(AuxiliaryPSPlayers,self).__init__()\n",
    "        \n",
    "        #forwardで使用する画像サイズ\n",
    "        self.height=height\n",
    "        self.width=width\n",
    "        \n",
    "        self.cbr=conv2DBatchNormRelu(in_channels=in_channels,out_channels=256,kernel_size=3,stride=1,padding=1,dilation=1,bias=False)\n",
    "        self.dropout=nn.Dropout2d(p=0.1)\n",
    "        self.classification=nn.Conv2d(in_channels=256,out_channels=n_classes,kernel_size=1,stride=1,padding=0)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        x=self.cbr(x)\n",
    "        x=self.dropout(x)\n",
    "        x=self.classification(x)\n",
    "        output=F.interpolate(x,size=(self.height,self.width),mode=\"bilinear\", align_corners=True)\n",
    "        \n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PSPNet(\n",
       "  (feature_conv): FeatureMap_convolution(\n",
       "    (cbnr_1): conv2DBatchNormRelu(\n",
       "      (conv): Conv2d(3, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (batchnorm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (cbnr_2): conv2DBatchNormRelu(\n",
       "      (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (batchnorm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (cbnr_3): conv2DBatchNormRelu(\n",
       "      (conv): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (batchnorm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (feature_res_1): ResidualBlockPSP(\n",
       "    (block1): bottleNeckPSP(\n",
       "      (cbr_1): conv2DBatchNormRelu(\n",
       "        (conv): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (batchnorm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (cbr_2): conv2DBatchNormRelu(\n",
       "        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (batchnorm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (cb_3): conv2DBatchNorm(\n",
       "        (conv): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (batchnorm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (cb_residual): conv2DBatchNorm(\n",
       "        (conv): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (batchnorm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (block2): bottleNeckIdentifyPSP(\n",
       "      (cbr_1): conv2DBatchNormRelu(\n",
       "        (conv): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (batchnorm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (cbr_2): conv2DBatchNormRelu(\n",
       "        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (batchnorm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (cb_3): conv2DBatchNorm(\n",
       "        (conv): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (batchnorm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (block3): bottleNeckIdentifyPSP(\n",
       "      (cbr_1): conv2DBatchNormRelu(\n",
       "        (conv): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (batchnorm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (cbr_2): conv2DBatchNormRelu(\n",
       "        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (batchnorm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (cb_3): conv2DBatchNorm(\n",
       "        (conv): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (batchnorm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (feature_res_2): ResidualBlockPSP(\n",
       "    (block1): bottleNeckPSP(\n",
       "      (cbr_1): conv2DBatchNormRelu(\n",
       "        (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (batchnorm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (cbr_2): conv2DBatchNormRelu(\n",
       "        (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (batchnorm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (cb_3): conv2DBatchNorm(\n",
       "        (conv): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (batchnorm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (cb_residual): conv2DBatchNorm(\n",
       "        (conv): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (batchnorm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (block2): bottleNeckIdentifyPSP(\n",
       "      (cbr_1): conv2DBatchNormRelu(\n",
       "        (conv): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (batchnorm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (cbr_2): conv2DBatchNormRelu(\n",
       "        (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (batchnorm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (cb_3): conv2DBatchNorm(\n",
       "        (conv): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (batchnorm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (block3): bottleNeckIdentifyPSP(\n",
       "      (cbr_1): conv2DBatchNormRelu(\n",
       "        (conv): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (batchnorm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (cbr_2): conv2DBatchNormRelu(\n",
       "        (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (batchnorm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (cb_3): conv2DBatchNorm(\n",
       "        (conv): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (batchnorm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (block4): bottleNeckIdentifyPSP(\n",
       "      (cbr_1): conv2DBatchNormRelu(\n",
       "        (conv): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (batchnorm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (cbr_2): conv2DBatchNormRelu(\n",
       "        (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (batchnorm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (cb_3): conv2DBatchNorm(\n",
       "        (conv): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (batchnorm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (feature_dilated_res_1): ResidualBlockPSP(\n",
       "    (block1): bottleNeckPSP(\n",
       "      (cbr_1): conv2DBatchNormRelu(\n",
       "        (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (batchnorm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (cbr_2): conv2DBatchNormRelu(\n",
       "        (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
       "        (batchnorm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (cb_3): conv2DBatchNorm(\n",
       "        (conv): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (batchnorm): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (cb_residual): conv2DBatchNorm(\n",
       "        (conv): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (batchnorm): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (block2): bottleNeckIdentifyPSP(\n",
       "      (cbr_1): conv2DBatchNormRelu(\n",
       "        (conv): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (batchnorm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (cbr_2): conv2DBatchNormRelu(\n",
       "        (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
       "        (batchnorm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (cb_3): conv2DBatchNorm(\n",
       "        (conv): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (batchnorm): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (block3): bottleNeckIdentifyPSP(\n",
       "      (cbr_1): conv2DBatchNormRelu(\n",
       "        (conv): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (batchnorm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (cbr_2): conv2DBatchNormRelu(\n",
       "        (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
       "        (batchnorm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (cb_3): conv2DBatchNorm(\n",
       "        (conv): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (batchnorm): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (block4): bottleNeckIdentifyPSP(\n",
       "      (cbr_1): conv2DBatchNormRelu(\n",
       "        (conv): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (batchnorm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (cbr_2): conv2DBatchNormRelu(\n",
       "        (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
       "        (batchnorm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (cb_3): conv2DBatchNorm(\n",
       "        (conv): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (batchnorm): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (block5): bottleNeckIdentifyPSP(\n",
       "      (cbr_1): conv2DBatchNormRelu(\n",
       "        (conv): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (batchnorm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (cbr_2): conv2DBatchNormRelu(\n",
       "        (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
       "        (batchnorm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (cb_3): conv2DBatchNorm(\n",
       "        (conv): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (batchnorm): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (block6): bottleNeckIdentifyPSP(\n",
       "      (cbr_1): conv2DBatchNormRelu(\n",
       "        (conv): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (batchnorm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (cbr_2): conv2DBatchNormRelu(\n",
       "        (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
       "        (batchnorm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (cb_3): conv2DBatchNorm(\n",
       "        (conv): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (batchnorm): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (feature_dilated_res_2): ResidualBlockPSP(\n",
       "    (block1): bottleNeckPSP(\n",
       "      (cbr_1): conv2DBatchNormRelu(\n",
       "        (conv): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (batchnorm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (cbr_2): conv2DBatchNormRelu(\n",
       "        (conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(4, 4), dilation=(4, 4), bias=False)\n",
       "        (batchnorm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (cb_3): conv2DBatchNorm(\n",
       "        (conv): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (batchnorm): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (cb_residual): conv2DBatchNorm(\n",
       "        (conv): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (batchnorm): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (block2): bottleNeckIdentifyPSP(\n",
       "      (cbr_1): conv2DBatchNormRelu(\n",
       "        (conv): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (batchnorm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (cbr_2): conv2DBatchNormRelu(\n",
       "        (conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(4, 4), dilation=(4, 4), bias=False)\n",
       "        (batchnorm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (cb_3): conv2DBatchNorm(\n",
       "        (conv): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (batchnorm): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (block3): bottleNeckIdentifyPSP(\n",
       "      (cbr_1): conv2DBatchNormRelu(\n",
       "        (conv): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (batchnorm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (cbr_2): conv2DBatchNormRelu(\n",
       "        (conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(4, 4), dilation=(4, 4), bias=False)\n",
       "        (batchnorm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (cb_3): conv2DBatchNorm(\n",
       "        (conv): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (batchnorm): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (pyramid_pooling): PyramidPooling(\n",
       "    (avpool_1): AdaptiveAvgPool2d(output_size=6)\n",
       "    (cbr_1): conv2DBatchNormRelu(\n",
       "      (conv): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (batchnorm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (avpool_2): AdaptiveAvgPool2d(output_size=3)\n",
       "    (cbr_2): conv2DBatchNormRelu(\n",
       "      (conv): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (batchnorm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (avpool_3): AdaptiveAvgPool2d(output_size=2)\n",
       "    (cbr_3): conv2DBatchNormRelu(\n",
       "      (conv): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (batchnorm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (avpool_4): AdaptiveAvgPool2d(output_size=1)\n",
       "    (cbr_4): conv2DBatchNormRelu(\n",
       "      (conv): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (batchnorm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (decode_feature): DecoderPSPFeature(\n",
       "    (cbr): conv2DBatchNormRelu(\n",
       "      (conv): Conv2d(4096, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (batchnorm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (dropout): Dropout2d(p=0.1, inplace=False)\n",
       "    (classification): Conv2d(512, 21, kernel_size=(1, 1), stride=(1, 1))\n",
       "  )\n",
       "  (aux): AuxiliaryPSPlayers(\n",
       "    (cbr): conv2DBatchNormRelu(\n",
       "      (conv): Conv2d(1024, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (batchnorm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (dropout): Dropout2d(p=0.1, inplace=False)\n",
       "    (classification): Conv2d(256, 21, kernel_size=(1, 1), stride=(1, 1))\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#モデルの定義\n",
    "net=PSPNet(n_classes=21)\n",
    "net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor([[[[ 1.3197e-02, -6.6432e-02, -1.4606e-01,  ..., -6.1516e-01,\n",
      "           -7.5884e-01, -9.0252e-01],\n",
      "          [ 4.7068e-02, -3.0706e-02, -1.0848e-01,  ..., -6.0683e-01,\n",
      "           -7.2635e-01, -8.4587e-01],\n",
      "          [ 8.0939e-02,  5.0190e-03, -7.0901e-02,  ..., -5.9851e-01,\n",
      "           -6.9387e-01, -7.8923e-01],\n",
      "          ...,\n",
      "          [-8.5805e-02, -9.4103e-02, -1.0240e-01,  ..., -1.5974e-01,\n",
      "           -1.8867e-01, -2.1760e-01],\n",
      "          [-1.3517e-01, -1.4052e-01, -1.4586e-01,  ..., -1.5702e-01,\n",
      "           -1.8955e-01, -2.2209e-01],\n",
      "          [-1.8454e-01, -1.8693e-01, -1.8932e-01,  ..., -1.5430e-01,\n",
      "           -1.9044e-01, -2.2658e-01]],\n",
      "\n",
      "         [[-3.2306e-02, -5.6774e-02, -8.1242e-02,  ..., -4.2991e-01,\n",
      "           -3.9045e-01, -3.5098e-01],\n",
      "          [-8.3814e-03, -4.9226e-02, -9.0070e-02,  ..., -3.9964e-01,\n",
      "           -3.6800e-01, -3.3636e-01],\n",
      "          [ 1.5543e-02, -4.1678e-02, -9.8899e-02,  ..., -3.6936e-01,\n",
      "           -3.4555e-01, -3.2174e-01],\n",
      "          ...,\n",
      "          [-3.5292e-02, -6.0564e-03,  2.3179e-02,  ..., -2.6722e-01,\n",
      "           -3.2872e-01, -3.9022e-01],\n",
      "          [-2.1911e-03,  2.2619e-02,  4.7429e-02,  ..., -2.4208e-01,\n",
      "           -3.1010e-01, -3.7812e-01],\n",
      "          [ 3.0910e-02,  5.1294e-02,  7.1679e-02,  ..., -2.1693e-01,\n",
      "           -2.9147e-01, -3.6602e-01]],\n",
      "\n",
      "         [[-7.5636e-01, -7.2874e-01, -7.0111e-01,  ..., -3.5689e-01,\n",
      "           -3.1474e-01, -2.7258e-01],\n",
      "          [-6.9925e-01, -6.7032e-01, -6.4139e-01,  ..., -2.7358e-01,\n",
      "           -2.3628e-01, -1.9898e-01],\n",
      "          [-6.4215e-01, -6.1191e-01, -5.8167e-01,  ..., -1.9026e-01,\n",
      "           -1.5782e-01, -1.2538e-01],\n",
      "          ...,\n",
      "          [-2.3432e-01, -1.7947e-01, -1.2461e-01,  ...,  6.8292e-02,\n",
      "            9.2048e-02,  1.1580e-01],\n",
      "          [-2.3964e-01, -1.7530e-01, -1.1097e-01,  ...,  7.6247e-02,\n",
      "            9.5637e-02,  1.1503e-01],\n",
      "          [-2.4495e-01, -1.7114e-01, -9.7325e-02,  ...,  8.4202e-02,\n",
      "            9.9227e-02,  1.1425e-01]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 3.1741e-01,  3.2700e-01,  3.3659e-01,  ...,  1.2846e-01,\n",
      "            1.4908e-01,  1.6969e-01],\n",
      "          [ 3.0345e-01,  3.0414e-01,  3.0482e-01,  ...,  9.2364e-02,\n",
      "            1.1518e-01,  1.3799e-01],\n",
      "          [ 2.8950e-01,  2.8127e-01,  2.7305e-01,  ...,  5.6273e-02,\n",
      "            8.1281e-02,  1.0629e-01],\n",
      "          ...,\n",
      "          [ 3.4522e-01,  3.2792e-01,  3.1063e-01,  ...,  5.9679e-02,\n",
      "            2.2853e-02, -1.3972e-02],\n",
      "          [ 2.7310e-01,  2.6355e-01,  2.5400e-01,  ...,  9.4422e-02,\n",
      "            5.9032e-02,  2.3642e-02],\n",
      "          [ 2.0098e-01,  1.9917e-01,  1.9736e-01,  ...,  1.2916e-01,\n",
      "            9.5211e-02,  6.1257e-02]],\n",
      "\n",
      "         [[-4.0824e-02, -6.1543e-02, -8.2261e-02,  ...,  4.9429e-02,\n",
      "            7.5123e-02,  1.0082e-01],\n",
      "          [-3.4572e-02, -5.9276e-02, -8.3981e-02,  ...,  3.3175e-02,\n",
      "            5.8657e-02,  8.4139e-02],\n",
      "          [-2.8320e-02, -5.7010e-02, -8.5700e-02,  ...,  1.6921e-02,\n",
      "            4.2191e-02,  6.7461e-02],\n",
      "          ...,\n",
      "          [ 3.5291e-01,  3.2336e-01,  2.9381e-01,  ...,  5.4482e-01,\n",
      "            6.1250e-01,  6.8019e-01],\n",
      "          [ 3.7441e-01,  3.4615e-01,  3.1790e-01,  ...,  5.7338e-01,\n",
      "            6.4943e-01,  7.2547e-01],\n",
      "          [ 3.9591e-01,  3.6895e-01,  3.4198e-01,  ...,  6.0195e-01,\n",
      "            6.8635e-01,  7.7076e-01]],\n",
      "\n",
      "         [[ 2.9437e-01,  3.0350e-01,  3.1263e-01,  ...,  3.8311e-01,\n",
      "            4.4100e-01,  4.9889e-01],\n",
      "          [ 2.4845e-01,  2.5626e-01,  2.6407e-01,  ...,  3.5790e-01,\n",
      "            4.1273e-01,  4.6756e-01],\n",
      "          [ 2.0252e-01,  2.0902e-01,  2.1551e-01,  ...,  3.3270e-01,\n",
      "            3.8447e-01,  4.3624e-01],\n",
      "          ...,\n",
      "          [-1.6638e-01, -1.5784e-01, -1.4931e-01,  ...,  4.7402e-01,\n",
      "            5.1544e-01,  5.5686e-01],\n",
      "          [-2.1584e-01, -1.8497e-01, -1.5410e-01,  ...,  5.0656e-01,\n",
      "            5.4907e-01,  5.9158e-01],\n",
      "          [-2.6531e-01, -2.1210e-01, -1.5889e-01,  ...,  5.3910e-01,\n",
      "            5.8270e-01,  6.2630e-01]]],\n",
      "\n",
      "\n",
      "        [[[-6.2112e-01, -6.0631e-01, -5.9149e-01,  ..., -5.3965e-01,\n",
      "           -6.2560e-01, -7.1155e-01],\n",
      "          [-6.0007e-01, -5.9000e-01, -5.7993e-01,  ..., -5.2231e-01,\n",
      "           -5.9897e-01, -6.7563e-01],\n",
      "          [-5.7902e-01, -5.7369e-01, -5.6837e-01,  ..., -5.0498e-01,\n",
      "           -5.7235e-01, -6.3972e-01],\n",
      "          ...,\n",
      "          [-2.5090e-01, -2.2139e-01, -1.9188e-01,  ..., -3.7985e-01,\n",
      "           -3.7100e-01, -3.6216e-01],\n",
      "          [-2.5529e-01, -2.2761e-01, -1.9992e-01,  ..., -3.6358e-01,\n",
      "           -3.3989e-01, -3.1621e-01],\n",
      "          [-2.5968e-01, -2.3383e-01, -2.0797e-01,  ..., -3.4731e-01,\n",
      "           -3.0878e-01, -2.7026e-01]],\n",
      "\n",
      "         [[ 8.3112e-01,  7.6192e-01,  6.9272e-01,  ...,  1.3860e-01,\n",
      "            7.5247e-02,  1.1896e-02],\n",
      "          [ 7.5308e-01,  6.8927e-01,  6.2547e-01,  ...,  1.6106e-01,\n",
      "            1.0781e-01,  5.4559e-02],\n",
      "          [ 6.7503e-01,  6.1663e-01,  5.5822e-01,  ...,  1.8352e-01,\n",
      "            1.4037e-01,  9.7222e-02],\n",
      "          ...,\n",
      "          [ 3.5516e-01,  3.0258e-01,  2.4999e-01,  ...,  2.0353e-01,\n",
      "            2.2791e-01,  2.5229e-01],\n",
      "          [ 3.4624e-01,  2.9449e-01,  2.4274e-01,  ...,  2.2643e-01,\n",
      "            2.4373e-01,  2.6103e-01],\n",
      "          [ 3.3733e-01,  2.8641e-01,  2.3548e-01,  ...,  2.4932e-01,\n",
      "            2.5955e-01,  2.6977e-01]],\n",
      "\n",
      "         [[-4.7181e-01, -4.1129e-01, -3.5078e-01,  ..., -2.6052e-01,\n",
      "           -3.1118e-01, -3.6184e-01],\n",
      "          [-4.0992e-01, -3.6267e-01, -3.1542e-01,  ..., -2.3177e-01,\n",
      "           -2.8376e-01, -3.3575e-01],\n",
      "          [-3.4804e-01, -3.1405e-01, -2.8007e-01,  ..., -2.0301e-01,\n",
      "           -2.5633e-01, -3.0966e-01],\n",
      "          ...,\n",
      "          [-1.8454e-03,  6.7157e-05,  1.9797e-03,  ..., -2.8788e-01,\n",
      "           -3.3229e-01, -3.7669e-01],\n",
      "          [-9.8904e-03, -4.9837e-03, -7.6924e-05,  ..., -2.7397e-01,\n",
      "           -3.2121e-01, -3.6845e-01],\n",
      "          [-1.7935e-02, -1.0034e-02, -2.1336e-03,  ..., -2.6005e-01,\n",
      "           -3.1013e-01, -3.6021e-01]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 3.6562e-01,  3.3947e-01,  3.1333e-01,  ...,  3.4783e-01,\n",
      "            3.5164e-01,  3.5545e-01],\n",
      "          [ 2.9659e-01,  2.7719e-01,  2.5778e-01,  ...,  3.0681e-01,\n",
      "            3.1215e-01,  3.1750e-01],\n",
      "          [ 2.2757e-01,  2.1490e-01,  2.0223e-01,  ...,  2.6578e-01,\n",
      "            2.7267e-01,  2.7955e-01],\n",
      "          ...,\n",
      "          [ 2.5264e-01,  2.2757e-01,  2.0250e-01,  ..., -2.1334e-01,\n",
      "           -2.1073e-01, -2.0811e-01],\n",
      "          [ 2.0588e-01,  1.8929e-01,  1.7270e-01,  ..., -2.6407e-01,\n",
      "           -2.5283e-01, -2.4159e-01],\n",
      "          [ 1.5912e-01,  1.5101e-01,  1.4290e-01,  ..., -3.1480e-01,\n",
      "           -2.9494e-01, -2.7507e-01]],\n",
      "\n",
      "         [[-3.0843e-01, -3.1735e-01, -3.2627e-01,  ...,  1.4552e-01,\n",
      "            1.9025e-01,  2.3498e-01],\n",
      "          [-2.7169e-01, -2.7751e-01, -2.8334e-01,  ...,  1.1823e-01,\n",
      "            1.5082e-01,  1.8340e-01],\n",
      "          [-2.3494e-01, -2.3768e-01, -2.4042e-01,  ...,  9.0946e-02,\n",
      "            1.1139e-01,  1.3183e-01],\n",
      "          ...,\n",
      "          [ 4.2903e-01,  3.9436e-01,  3.5969e-01,  ...,  7.2113e-01,\n",
      "            7.6341e-01,  8.0570e-01],\n",
      "          [ 4.0478e-01,  3.7506e-01,  3.4535e-01,  ...,  7.4758e-01,\n",
      "            7.8878e-01,  8.2999e-01],\n",
      "          [ 3.8053e-01,  3.5577e-01,  3.3100e-01,  ...,  7.7403e-01,\n",
      "            8.1415e-01,  8.5428e-01]],\n",
      "\n",
      "         [[-1.7464e-01, -1.4578e-01, -1.1692e-01,  ...,  2.3776e-01,\n",
      "            2.6470e-01,  2.9164e-01],\n",
      "          [-1.6187e-01, -1.3101e-01, -1.0016e-01,  ...,  2.6406e-01,\n",
      "            2.9620e-01,  3.2835e-01],\n",
      "          [-1.4909e-01, -1.1625e-01, -8.3402e-02,  ...,  2.9035e-01,\n",
      "            3.2770e-01,  3.6505e-01],\n",
      "          ...,\n",
      "          [ 2.9923e-01,  2.9353e-01,  2.8783e-01,  ...,  2.5783e-01,\n",
      "            2.4226e-01,  2.2670e-01],\n",
      "          [ 3.3991e-01,  3.3800e-01,  3.3609e-01,  ...,  2.7549e-01,\n",
      "            2.5516e-01,  2.3484e-01],\n",
      "          [ 3.8059e-01,  3.8247e-01,  3.8435e-01,  ...,  2.9315e-01,\n",
      "            2.6806e-01,  2.4298e-01]]]], grad_fn=<UpsampleBilinear2DBackward>), tensor([[[[-5.0491e-02, -8.2795e-02, -1.1510e-01,  ...,  2.3234e-01,\n",
      "            3.1038e-01,  3.8841e-01],\n",
      "          [-1.0215e-01, -1.2499e-01, -1.4782e-01,  ...,  2.2818e-01,\n",
      "            2.9553e-01,  3.6289e-01],\n",
      "          [-1.5382e-01, -1.6718e-01, -1.8054e-01,  ...,  2.2402e-01,\n",
      "            2.8069e-01,  3.3736e-01],\n",
      "          ...,\n",
      "          [-4.3738e-01, -4.1986e-01, -4.0234e-01,  ..., -3.7984e-02,\n",
      "           -2.9429e-03,  3.2098e-02],\n",
      "          [-4.5930e-01, -4.4714e-01, -4.3497e-01,  ..., -1.0135e-01,\n",
      "           -6.8126e-02, -3.4900e-02],\n",
      "          [-4.8123e-01, -4.7442e-01, -4.6760e-01,  ..., -1.6472e-01,\n",
      "           -1.3331e-01, -1.0190e-01]],\n",
      "\n",
      "         [[ 4.8692e-01,  4.4155e-01,  3.9619e-01,  ...,  6.0358e-02,\n",
      "            6.9959e-02,  7.9560e-02],\n",
      "          [ 5.0280e-01,  4.5845e-01,  4.1410e-01,  ...,  6.0009e-02,\n",
      "            7.0255e-02,  8.0502e-02],\n",
      "          [ 5.1868e-01,  4.7535e-01,  4.3202e-01,  ...,  5.9660e-02,\n",
      "            7.0552e-02,  8.1443e-02],\n",
      "          ...,\n",
      "          [ 2.2209e-01,  2.7114e-01,  3.2018e-01,  ...,  3.8071e-01,\n",
      "            3.8174e-01,  3.8276e-01],\n",
      "          [ 1.9025e-01,  2.4351e-01,  2.9677e-01,  ...,  4.3886e-01,\n",
      "            4.4163e-01,  4.4441e-01],\n",
      "          [ 1.5840e-01,  2.1588e-01,  2.7336e-01,  ...,  4.9701e-01,\n",
      "            5.0153e-01,  5.0605e-01]],\n",
      "\n",
      "         [[-9.9739e-01, -9.4458e-01, -8.9178e-01,  ..., -1.2091e+00,\n",
      "           -1.2410e+00, -1.2728e+00],\n",
      "          [-9.6575e-01, -9.0913e-01, -8.5252e-01,  ..., -1.1893e+00,\n",
      "           -1.2188e+00, -1.2483e+00],\n",
      "          [-9.3411e-01, -8.7368e-01, -8.1325e-01,  ..., -1.1694e+00,\n",
      "           -1.1966e+00, -1.2238e+00],\n",
      "          ...,\n",
      "          [-2.8603e-01, -2.8915e-01, -2.9228e-01,  ..., -7.4188e-01,\n",
      "           -7.4734e-01, -7.5279e-01],\n",
      "          [-3.0122e-01, -3.0735e-01, -3.1349e-01,  ..., -7.4614e-01,\n",
      "           -7.4163e-01, -7.3712e-01],\n",
      "          [-3.1640e-01, -3.2555e-01, -3.3469e-01,  ..., -7.5040e-01,\n",
      "           -7.3593e-01, -7.2145e-01]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-4.7783e-01, -3.9350e-01, -3.0916e-01,  ..., -2.9355e-01,\n",
      "           -3.3529e-01, -3.7703e-01],\n",
      "          [-4.8094e-01, -3.9419e-01, -3.0743e-01,  ..., -2.6136e-01,\n",
      "           -2.9346e-01, -3.2556e-01],\n",
      "          [-4.8405e-01, -3.9488e-01, -3.0571e-01,  ..., -2.2917e-01,\n",
      "           -2.5163e-01, -2.7409e-01],\n",
      "          ...,\n",
      "          [ 5.1524e-02,  3.3474e-02,  1.5425e-02,  ...,  1.9892e-01,\n",
      "            1.9978e-01,  2.0063e-01],\n",
      "          [ 1.0556e-01,  8.2695e-02,  5.9830e-02,  ...,  2.2313e-01,\n",
      "            2.2168e-01,  2.2023e-01],\n",
      "          [ 1.5960e-01,  1.3192e-01,  1.0424e-01,  ...,  2.4734e-01,\n",
      "            2.4358e-01,  2.3983e-01]],\n",
      "\n",
      "         [[ 3.6459e-01,  3.5109e-01,  3.3758e-01,  ...,  7.2214e-02,\n",
      "            2.8574e-02, -1.5065e-02],\n",
      "          [ 3.0766e-01,  3.0013e-01,  2.9260e-01,  ...,  6.7323e-02,\n",
      "            2.8338e-02, -1.0646e-02],\n",
      "          [ 2.5073e-01,  2.4917e-01,  2.4761e-01,  ...,  6.2432e-02,\n",
      "            2.8103e-02, -6.2268e-03],\n",
      "          ...,\n",
      "          [-1.4013e-01, -1.1027e-01, -8.0414e-02,  ...,  1.0838e-01,\n",
      "            1.0398e-01,  9.9577e-02],\n",
      "          [-1.1286e-01, -9.3016e-02, -7.3170e-02,  ...,  5.8928e-02,\n",
      "            5.2325e-02,  4.5722e-02],\n",
      "          [-8.5597e-02, -7.5761e-02, -6.5925e-02,  ...,  9.4790e-03,\n",
      "            6.7238e-04, -8.1342e-03]],\n",
      "\n",
      "         [[-4.5310e-02, -6.6774e-02, -8.8238e-02,  ..., -8.2735e-02,\n",
      "           -1.3238e-01, -1.8203e-01],\n",
      "          [-1.8978e-02, -3.4668e-02, -5.0359e-02,  ..., -1.1030e-01,\n",
      "           -1.6527e-01, -2.2024e-01],\n",
      "          [ 7.3539e-03, -2.5627e-03, -1.2479e-02,  ..., -1.3787e-01,\n",
      "           -1.9816e-01, -2.5845e-01],\n",
      "          ...,\n",
      "          [-5.9020e-02, -4.7268e-02, -3.5517e-02,  ..., -4.7413e-01,\n",
      "           -5.6594e-01, -6.5776e-01],\n",
      "          [-6.6311e-02, -5.7968e-02, -4.9625e-02,  ..., -5.7743e-01,\n",
      "           -6.6968e-01, -7.6193e-01],\n",
      "          [-7.3601e-02, -6.8667e-02, -6.3733e-02,  ..., -6.8073e-01,\n",
      "           -7.7342e-01, -8.6611e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 6.6672e-03,  2.5282e-02,  4.3897e-02,  ...,  2.0207e-01,\n",
      "            2.7390e-01,  3.4574e-01],\n",
      "          [-2.2874e-02, -4.7735e-03,  1.3327e-02,  ...,  2.0837e-01,\n",
      "            2.7646e-01,  3.4455e-01],\n",
      "          [-5.2415e-02, -3.4829e-02, -1.7243e-02,  ...,  2.1467e-01,\n",
      "            2.7901e-01,  3.4336e-01],\n",
      "          ...,\n",
      "          [-1.4932e-01, -1.1778e-01, -8.6245e-02,  ...,  3.1424e-01,\n",
      "            3.5923e-01,  4.0421e-01],\n",
      "          [-1.5763e-01, -1.2811e-01, -9.8593e-02,  ...,  3.2318e-01,\n",
      "            3.6303e-01,  4.0288e-01],\n",
      "          [-1.6593e-01, -1.3844e-01, -1.1094e-01,  ...,  3.3213e-01,\n",
      "            3.6684e-01,  4.0155e-01]],\n",
      "\n",
      "         [[ 9.2164e-01,  8.5251e-01,  7.8339e-01,  ...,  3.2513e-01,\n",
      "            4.0889e-01,  4.9266e-01],\n",
      "          [ 8.8632e-01,  8.2620e-01,  7.6609e-01,  ...,  2.7371e-01,\n",
      "            3.4080e-01,  4.0789e-01],\n",
      "          [ 8.5100e-01,  7.9990e-01,  7.4879e-01,  ...,  2.2230e-01,\n",
      "            2.7270e-01,  3.2311e-01],\n",
      "          ...,\n",
      "          [ 2.1217e-01,  2.3413e-01,  2.5610e-01,  ...,  6.1494e-01,\n",
      "            6.3137e-01,  6.4780e-01],\n",
      "          [ 2.1863e-01,  2.2230e-01,  2.2598e-01,  ...,  6.4758e-01,\n",
      "            6.6513e-01,  6.8269e-01],\n",
      "          [ 2.2508e-01,  2.1047e-01,  1.9586e-01,  ...,  6.8022e-01,\n",
      "            6.9890e-01,  7.1758e-01]],\n",
      "\n",
      "         [[-6.6681e-01, -7.0051e-01, -7.3421e-01,  ..., -1.1694e+00,\n",
      "           -1.2138e+00, -1.2581e+00],\n",
      "          [-6.5510e-01, -6.8604e-01, -7.1697e-01,  ..., -1.1320e+00,\n",
      "           -1.1767e+00, -1.2214e+00],\n",
      "          [-6.4338e-01, -6.7156e-01, -6.9974e-01,  ..., -1.0946e+00,\n",
      "           -1.1397e+00, -1.1847e+00],\n",
      "          ...,\n",
      "          [-5.9730e-01, -6.0919e-01, -6.2109e-01,  ..., -6.3480e-01,\n",
      "           -6.8443e-01, -7.3405e-01],\n",
      "          [-5.5132e-01, -5.7194e-01, -5.9256e-01,  ..., -6.0598e-01,\n",
      "           -6.6089e-01, -7.1580e-01],\n",
      "          [-5.0534e-01, -5.3468e-01, -5.6402e-01,  ..., -5.7715e-01,\n",
      "           -6.3735e-01, -6.9755e-01]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-1.2878e-01, -1.1993e-01, -1.1108e-01,  ..., -2.9124e-01,\n",
      "           -3.2399e-01, -3.5673e-01],\n",
      "          [-1.4550e-01, -1.3916e-01, -1.3281e-01,  ..., -2.8024e-01,\n",
      "           -3.0781e-01, -3.3538e-01],\n",
      "          [-1.6221e-01, -1.5838e-01, -1.5455e-01,  ..., -2.6924e-01,\n",
      "           -2.9163e-01, -3.1403e-01],\n",
      "          ...,\n",
      "          [ 1.4784e-01,  1.1819e-01,  8.8539e-02,  ..., -5.8293e-02,\n",
      "           -5.1940e-02, -4.5587e-02],\n",
      "          [ 1.1277e-01,  9.7083e-02,  8.1401e-02,  ..., -4.5459e-02,\n",
      "           -4.3314e-02, -4.1169e-02],\n",
      "          [ 7.7691e-02,  7.5977e-02,  7.4262e-02,  ..., -3.2624e-02,\n",
      "           -3.4688e-02, -3.6751e-02]],\n",
      "\n",
      "         [[ 2.2463e-02,  2.8358e-02,  3.4253e-02,  ...,  1.1293e-01,\n",
      "            1.2607e-01,  1.3921e-01],\n",
      "          [ 2.3121e-02,  3.2783e-02,  4.2445e-02,  ...,  8.9762e-02,\n",
      "            1.1173e-01,  1.3369e-01],\n",
      "          [ 2.3779e-02,  3.7208e-02,  5.0636e-02,  ...,  6.6597e-02,\n",
      "            9.7390e-02,  1.2818e-01],\n",
      "          ...,\n",
      "          [ 4.5775e-02,  7.7812e-02,  1.0985e-01,  ..., -2.1418e-02,\n",
      "            6.6096e-04,  2.2740e-02],\n",
      "          [ 5.8370e-02,  8.9930e-02,  1.2149e-01,  ..., -2.0327e-02,\n",
      "            2.6368e-03,  2.5601e-02],\n",
      "          [ 7.0965e-02,  1.0205e-01,  1.3313e-01,  ..., -1.9237e-02,\n",
      "            4.6126e-03,  2.8462e-02]],\n",
      "\n",
      "         [[ 4.7193e-02,  3.4880e-02,  2.2567e-02,  ...,  2.6106e-01,\n",
      "            2.7469e-01,  2.8831e-01],\n",
      "          [-1.7081e-02, -2.0317e-02, -2.3553e-02,  ...,  1.9585e-01,\n",
      "            2.1311e-01,  2.3038e-01],\n",
      "          [-8.1355e-02, -7.5514e-02, -6.9673e-02,  ...,  1.3063e-01,\n",
      "            1.5154e-01,  1.7244e-01],\n",
      "          ...,\n",
      "          [ 4.5976e-02,  4.4021e-02,  4.2065e-02,  ..., -1.0491e-01,\n",
      "           -1.0802e-01, -1.1114e-01],\n",
      "          [ 7.4271e-02,  6.8165e-02,  6.2060e-02,  ..., -1.7798e-01,\n",
      "           -1.7550e-01, -1.7301e-01],\n",
      "          [ 1.0257e-01,  9.2310e-02,  8.2056e-02,  ..., -2.5105e-01,\n",
      "           -2.4297e-01, -2.3489e-01]]]], grad_fn=<UpsampleBilinear2DBackward>))\n"
     ]
    }
   ],
   "source": [
    "#ダミーデータの作成\n",
    "batch_size=2\n",
    "dummy_img=torch.rand(batch_size,3,475,475)\n",
    "\n",
    "#calc\n",
    "outputs=net(dummy_img)\n",
    "print(outputs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
